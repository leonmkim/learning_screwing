{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb07bd03-939a-4c5f-9719-6c94490aebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4e6d0c-9534-4153-9956-5030e300c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "from bagpy import bagreader\n",
    "import rosbag\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88574e8c-9d56-403f-b461-f1f1abd2c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screwing_dataset import ScrewingDataset\n",
    "from screwing_model import ScrewingModel\n",
    "from screwing_model_seq import ScrewingModelSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e16476-b7b0-489a-baaa-2d069389904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e917ca09-f66d-4e20-9c36-ff6f940559af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import batched_pos_err, batched_ori_err, weighted_MSE_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd5a72d-098e-4ab0-bbd8-bed1ce94cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f957aae-d4a6-4054-bdce-04192a4b990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1 # Powers of two\n",
    "window_size = 30\n",
    "\n",
    "input_dim = 19\n",
    "hidden_dim = 10\n",
    "num_layers = 3\n",
    "output_dim = 5\n",
    "\n",
    "#TODO change arbitrary weight\n",
    "ori_rel_weight = 2\n",
    "\n",
    "num_eps = 2\n",
    "\n",
    "num_epochs = 200\n",
    "learning_rate = 0.003\n",
    "\n",
    "base_dset_dir = os.path.expanduser('~/datasets/screwing/')\n",
    "# xprmnt_dir = time.strftime(\"/2022-03-10_23-17-39\")\n",
    "# xprmnt_dir = time.strftime(\"2022-03-11_17-07-13/\")\n",
    "# xprmnt_dir = time.strftime(\"2022-04-04_14-40-37/\")\n",
    "xprmnt_dir = time.strftime(\"2022-04-14_15-49-01/\")\n",
    "\n",
    "\n",
    "log_interval = 1 \n",
    "\n",
    "train_ratio = .75\n",
    "\n",
    "\n",
    "model_save_dir = '../../../models/'\n",
    "model_name = 'model_2022-03-27_17-18-31.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70a244ca-790b-4f94-b728-80c0feabd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bagreader' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5278/1488959092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mpos_ori_path_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_path_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_ori_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print('about to load bag ' + str(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbagreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbagreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdset_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScrewingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ori_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_in_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bagreader' object is not callable"
     ]
    }
   ],
   "source": [
    "bag_path_names = base_dset_dir + xprmnt_dir + '*.bag' \n",
    "\n",
    "bag_path_list = glob.glob(bag_path_names)\n",
    "total_num_eps = len(bag_path_list)\n",
    "# wandb.config.update({'total_dset_eps_num': num_eps})\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "\n",
    "dset_list = []\n",
    "# for i in range(num_eps): # for testing a small number of data\n",
    "# for i in range(total_num_eps):\n",
    "i = 0\n",
    "id_str = str(i)\n",
    "print(i)\n",
    "bag_path_names = base_dset_dir + xprmnt_dir + id_str + '_*.bag' \n",
    "\n",
    "try:\n",
    "    bag_path = glob.glob(bag_path_names)[0]\n",
    "except:\n",
    "    print('bag with index ' + str(i) + ' was not found! Skipping to next index')\n",
    "\n",
    "pos_path_name = base_dset_dir + xprmnt_dir + id_str + '_pos.npy'\n",
    "proj_ori_path = base_dset_dir + xprmnt_dir + id_str + '_proj_ori.npy'\n",
    "pos_ori_path_list = [pos_path_name, proj_ori_path]\n",
    "# print('about to load bag ' + str(i))\n",
    "bagreader = bagreader(bag_path)\n",
    "try:\n",
    "    dset_i = ScrewingDataset(bag_path, pos_ori_path_list, window_size, overlapping=True, load_in_mem=True)\n",
    "    print(dset_i)\n",
    "    if len(dset_i) < 0:\n",
    "        print('bag has length < 0!: ' + bag_path)\n",
    "    else:\n",
    "        print('about to append')\n",
    "        dset_list.append(dset_i)\n",
    "except:\n",
    "    pass # TODO figure out a way to ensure the desired number of bags are added even if some bags fail to read\n",
    "\n",
    "# print(len(dset_list[-1])) \n",
    "print(dset_list)\n",
    "single_dset = dset_list[0]\n",
    "concat_dset = ConcatDataset(dset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c8ea3c1-1550-40bf-9fa1-d33a3a085633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Types</th>\n",
       "      <th>Message Count</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/clock</td>\n",
       "      <td>rosgraph_msgs/Clock</td>\n",
       "      <td>11322</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/panda/franka_state_controller_custom/franka_s...</td>\n",
       "      <td>franka_msgs/FrankaStateCustom</td>\n",
       "      <td>332</td>\n",
       "      <td>22.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/panda/franka_state_controller_custom/joint_st...</td>\n",
       "      <td>sensor_msgs/JointState</td>\n",
       "      <td>333</td>\n",
       "      <td>29.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/screwing_primitives/pose_desired</td>\n",
       "      <td>geometry_msgs/PoseStamped</td>\n",
       "      <td>2831</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tf</td>\n",
       "      <td>tf2_msgs/TFMessage</td>\n",
       "      <td>672</td>\n",
       "      <td>58.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/tf_static</td>\n",
       "      <td>tf2_msgs/TFMessage</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Topics  \\\n",
       "0                                             /clock   \n",
       "1  /panda/franka_state_controller_custom/franka_s...   \n",
       "2  /panda/franka_state_controller_custom/joint_st...   \n",
       "3                  /screwing_primitives/pose_desired   \n",
       "4                                                /tf   \n",
       "5                                         /tf_static   \n",
       "\n",
       "                           Types  Message Count    Frequency  \n",
       "0            rosgraph_msgs/Clock          11322  1000.000000  \n",
       "1  franka_msgs/FrankaStateCustom            332    22.727273  \n",
       "2         sensor_msgs/JointState            333    29.411765  \n",
       "3      geometry_msgs/PoseStamped           2831   250.000000  \n",
       "4             tf2_msgs/TFMessage            672    58.823529  \n",
       "5             tf2_msgs/TFMessage              3          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bagreader.message_by_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4accbae8-8ff8-4643-b9d5-142067b666b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bag_path_names = base_dset_dir + xprmnt_dir + '*.bag' \n",
    "\n",
    "# bag_path_list = glob.glob(bag_path_names)\n",
    "# total_num_eps = len(bag_path_list)\n",
    "# # wandb.config.update({'total_dset_eps_num': num_eps})\n",
    "\n",
    "# num_workers = 8\n",
    "\n",
    "# dset_list = []\n",
    "# for i in range(num_eps): # for testing a small number of data\n",
    "# # for i in range(total_num_eps):\n",
    "#     id_str = str(i)\n",
    "#     bag_path_names = base_dset_dir + xprmnt_dir + id_str + '_*.bag' \n",
    "#     bag_path = glob.glob(bag_path_names)[0]\n",
    "\n",
    "#     pos_path_name = base_dset_dir + xprmnt_dir + id_str + '_pos.npy'\n",
    "#     proj_ori_path = base_dset_dir + xprmnt_dir + id_str + '_proj_ori.npy'\n",
    "#     pos_ori_path_list = [pos_path_name, proj_ori_path]\n",
    "\n",
    "#     dset_list.append(ScrewingDataset(bag_path, pos_ori_path_list, run.config['window_size'], overlapping=run.config['overlapping'], load_in_mem=True))\n",
    "\n",
    "# concat_dset = ConcatDataset(dset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f81dd4b6-84db-45c1-b01f-03f4ae6519fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/serialexperimentsleon/datasets/screwing/2022-04-04_14-40-37/20_2022-04-04-14-46-49.bag'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_dset.datasets[0].bag_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b63a1a26-1430-42ee-93a4-eaf00baa79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lder = DataLoader(\n",
    "    single_dset,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5207c402-8dcd-477f-93c0-cd920eb2a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5725e-01, -5.0017e-04,  4.4767e-01,  9.9761e-01, -2.3399e-02,\n",
      "          6.3482e-02,  1.3864e-02],\n",
      "        [ 5.5890e-01, -9.3690e-04,  4.3692e-01,  9.9742e-01, -2.3270e-02,\n",
      "          6.6600e-02,  1.3393e-02],\n",
      "        [ 5.6084e-01, -1.4572e-03,  4.2435e-01,  9.9719e-01, -2.3150e-02,\n",
      "          7.0125e-02,  1.2693e-02],\n",
      "        [ 5.6308e-01, -1.7816e-03,  4.1023e-01,  9.9690e-01, -2.2955e-02,\n",
      "          7.4316e-02,  1.1800e-02],\n",
      "        [ 5.6588e-01, -1.8544e-03,  3.9536e-01,  9.9651e-01, -2.3160e-02,\n",
      "          7.9239e-02,  1.2377e-02]], dtype=torch.float64)\n",
      "tensor([[ 5.5890e-01, -9.3690e-04,  4.3692e-01,  9.9742e-01, -2.3270e-02,\n",
      "          6.6600e-02,  1.3393e-02],\n",
      "        [ 5.6084e-01, -1.4572e-03,  4.2435e-01,  9.9719e-01, -2.3150e-02,\n",
      "          7.0125e-02,  1.2693e-02],\n",
      "        [ 5.6308e-01, -1.7816e-03,  4.1023e-01,  9.9690e-01, -2.2955e-02,\n",
      "          7.4316e-02,  1.1800e-02],\n",
      "        [ 5.6588e-01, -1.8544e-03,  3.9536e-01,  9.9651e-01, -2.3160e-02,\n",
      "          7.9239e-02,  1.2377e-02],\n",
      "        [ 5.6638e-01, -2.5757e-03,  3.9383e-01,  9.9627e-01, -2.5669e-02,\n",
      "          8.0670e-02,  1.6606e-02]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# verify overlapping samples works\n",
    "len(single_dset)\n",
    "print(single_dset[146]['poses_wrenches_actions_tensor'][-5:, :7])\n",
    "print(single_dset[147]['poses_wrenches_actions_tensor'][-5:, :7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e174b2c0-2daf-4811-9a0f-a58a1a8ba945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "print(single_dset[146]['len_samples'])\n",
    "print(single_dset[147]['len_samples'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26ecc011-19b3-4859-8796-cc78b113a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "133\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, dict in enumerate(single_lder):\n",
    "    print(i)\n",
    "    print(dict['idx_accessed'].item())\n",
    "    print(dict['len_samples'].item())\n",
    "    # print(dict['bag_path'][0])\n",
    "    # print(dict['unnormed_times_np'][:, -1].item() - dict['unnormed_times_np'][:, 0].item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cece124-56c7-4bc2-9eec-e36fa0d9a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concat_lder = DataLoader(\n",
    "    concat_dset,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9785d0e7-6889-4bab-be46-751adc97d201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "for dset in concat_lder.dataset.datasets:\n",
    "    print(dset.bag_path.split('/')[-1].split('_')[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021c6cf6-cd13-4388-b111-fa817e648fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/serialexperimentsleon/datasets/screwing/2022-04-04_14-40-37/20_2022-04-04-14-46-49.bag\n"
     ]
    }
   ],
   "source": [
    "for i, dict in enumerate(concat_lder):\n",
    "    print(dict['bag_path'][0])\n",
    "    # print(dict['unnormed_times_np'][:, -1].item() - dict['unnormed_times_np'][:, 0].item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e974e1be-68c6-4c4a-aab8-2b642778d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(concat_dset)\n",
    "train_size = int(train_ratio*length)\n",
    "# train_size\n",
    "torch_seed = 0\n",
    "torch.manual_seed(torch_seed)\n",
    "train_dset, valid_dset = torch.utils.data.random_split(concat_dset, [train_size,length - train_size])\n",
    "train_dset_length = len(train_dset)\n",
    "valid_dset_length = len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "002a4235-9449-43da-8721-a17fc8cd8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_lder = DataLoader(\n",
    "    valid_dset,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e72ff0e6-9eea-478b-9d17-2375ba2404e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f9ffdc06890>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_lder.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "469a2a93-17ab-4e8d-8bee-bad94f2c16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScrewingModelSeq(input_dim, hidden_dim, num_layers, output_dim)\n",
    "model.load_state_dict(torch.load(model_save_dir + model_name))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3482796c-c545-4f89-9d14-5c2091050828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45473598110118224\n",
      "tensor([0.3854], device='cuda:0')\n",
      "0.32584792375564575\n",
      "0.4114879369735718\n",
      "13.464705228805542\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx,(x,y, times, T) in enumerate(valid_lder):\n",
    "        x = x.to(device)\n",
    "        y = y.float().to(device)\n",
    "\n",
    "        # Forward propogation happens here\n",
    "        outputs = model(x).to(device)\n",
    "        t = 0\n",
    "        # print(outputs.size())\n",
    "        output_t = outputs[:, t, :]\n",
    "        # print(output_t.size()) # B x L x O\n",
    "        # print(outputs[0, t, :].size()) # B x L x O\n",
    "        \n",
    "        # print(times.size()) # B x L \n",
    "        print(times[:, t].item()) \n",
    "        \n",
    "        loss = weighted_MSE_loss(output_t, y, ori_rel_weight)\n",
    "        print(batched_ori_err(output_t, y, device))\n",
    "        print(batched_pos_err(output_t, y).item())\n",
    "        print(loss.item())\n",
    "        print(T.item())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f85469-ef2d-4cb9-b180-9707bbd5a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_metrics(model, ori_rel_weight, seq_length, val_loader): #TODO add early stopping criterion\n",
    "#     # logging_step = 0\n",
    "#     # quantiles of interest: median and 95% CI\n",
    "#     q = torch.as_tensor([0.025, 0.5, 0.975]).to(device) \n",
    "#     q_timing = torch.as_tensor([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).to(device)\n",
    "#     seq_length = seq_length\n",
    "#     ## switch model to eval\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for batch_idx,(x,y, times) in enumerate(val_loader):\n",
    "#             x = x.to(device)\n",
    "#             y = y.float().to(device)\n",
    "\n",
    "#             # Forward propogation happens here\n",
    "#             outputs = model(x).to(device)\n",
    "#             for t in range(seq_length):\n",
    "\n",
    "#                 output_t = outputs[:, t, :]\n",
    "#                 times_t = times[:, t] \n",
    "\n",
    "#                 loss = weighted_MSE_loss(output_t, y, ori_rel_weight)\n",
    "\n",
    "#                 ## evaluate and append analysis metrics\n",
    "#                 total_valid_ori_error.append(batched_ori_err(output_t, y))\n",
    "#                 total_valid_pos_error.append(batched_pos_err(output_t, y))\n",
    "#                 total_valid_loss.append(loss)\n",
    "\n",
    "#                 # if batch_idx % log_interval == 0:\n",
    "#                 #     wandb.log({\"loss\": loss, 'epoch': epoch, 'batch_idx': batch_idx})\n",
    "                \n",
    "#                 total_valid_pos_error = torch.cat(total_valid_pos_error).to(device)\n",
    "#                 total_valid_ori_error = torch.cat(total_valid_ori_error).to(device)\n",
    "#                 total_valid_loss = torch.as_tensor(total_valid_loss).to(device)\n",
    "\n",
    "#                 ## statistical metrics from the test evaluations\n",
    "\n",
    "#                 ## pos error\n",
    "#                 pos_err_mean = torch.mean(total_valid_pos_error)\n",
    "#                 pos_err_std = torch.std(total_valid_pos_error)\n",
    "#                 pos_err_max = torch.max(total_valid_pos_error)\n",
    "#                 pos_err_min = torch.min(total_valid_pos_error)\n",
    "\n",
    "#                 ## 95% confidence interval and median\n",
    "#                 # q = torch.as_tensor([0.025, 0.5, 0.975]) \n",
    "#                 pos_err_95_median = torch.quantile(total_valid_pos_error, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 ## ori error\n",
    "#                 ori_err_mean = torch.mean(total_valid_ori_error)\n",
    "#                 ori_err_std = torch.std(total_valid_ori_error)\n",
    "#                 ori_err_max = torch.max(total_valid_ori_error)\n",
    "#                 ori_err_min = torch.min(total_valid_ori_error)\n",
    "\n",
    "#                 ## 95% confidence interval\n",
    "#                 ori_err_95_median = torch.quantile(total_valid_ori_error, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 ## loss \n",
    "#                 loss_mean = torch.mean(total_valid_loss)\n",
    "#                 loss_std = torch.std(total_valid_loss)\n",
    "#                 loss_max = torch.max(total_valid_loss)\n",
    "#                 loss_min = torch.min(total_valid_loss)\n",
    "\n",
    "#                 ## 95% confidence interval\n",
    "#                 loss_95_median = torch.quantile(total_valid_loss, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 wandb.log({ \n",
    "#                 'valid_pos_err_mean_' + str(t) : pos_err_mean,\n",
    "#                 'valid_pos_err_std_' + str(t) : pos_err_std,\n",
    "#                 'valid_pos_err_max_' + str(t) : pos_err_max,\n",
    "#                 'valid_pos_err_min_' + str(t) : pos_err_min,\n",
    "#                 'valid_pos_err_95_lower_' + str(t) : pos_err_95_median[0].item(),\n",
    "#                 'valid_pos_err_median_' + str(t) : pos_err_95_median[1].item(),\n",
    "#                 'valid_pos_err_95_upper_' + str(t) : pos_err_95_median[2].item(),\n",
    "#                 'valid_ori_err_mean_' + str(t) : ori_err_mean,\n",
    "#                 'valid_ori_err_std_' + str(t) : ori_err_std,\n",
    "#                 'valid_ori_err_max_' + str(t) : ori_err_max,\n",
    "#                 'valid_ori_err_min_' + str(t) : ori_err_min,\n",
    "#                 'valid_ori_err_95_lower_' + str(t) : ori_err_95_median[0].item(),\n",
    "#                 'valid_ori_err_median_' + str(t) : ori_err_95_median[1].item(),\n",
    "#                 'valid_ori_err_95_upper_' + str(t) : ori_err_95_median[2].item(),\n",
    "#                 'valid_loss_mean_' + str(t) : loss_mean,\n",
    "#                 'valid_loss_std_' + str(t) : loss_std,\n",
    "#                 'valid_loss_max_' + str(t) : loss_max,\n",
    "#                 'valid_loss_min_' + str(t) : loss_min,\n",
    "#                 'valid_loss_95_lower_' + str(t) : loss_95_median[0].item(),\n",
    "#                 'valid_loss_median_' + str(t) : loss_95_median[1].item(),\n",
    "#                 'valid_loss_95_upper_' + str(t) : loss_95_median[2].item()\n",
    "#                 }, step = logging_step-1)\n",
    "#                 ## log some summary metrics from the validation/eval run\n",
    "\n",
    "#                 ## log a figure of model output  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
