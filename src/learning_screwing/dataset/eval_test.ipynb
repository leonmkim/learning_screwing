{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb07bd03-939a-4c5f-9719-6c94490aebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4e6d0c-9534-4153-9956-5030e300c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load Python extension for LZ4 support. LZ4 compression will not be available.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "from bagpy import bagreader\n",
    "import rosbag\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88574e8c-9d56-403f-b461-f1f1abd2c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screwing_dataset import ScrewingDataset\n",
    "from screwing_model import ScrewingModel\n",
    "from screwing_model_seq import ScrewingModelSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41e16476-b7b0-489a-baaa-2d069389904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e917ca09-f66d-4e20-9c36-ff6f940559af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import batched_pos_err, batched_ori_err, weighted_MSE_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd5a72d-098e-4ab0-bbd8-bed1ce94cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f957aae-d4a6-4054-bdce-04192a4b990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1 # Powers of two\n",
    "window_size = 30\n",
    "\n",
    "input_dim = 19\n",
    "hidden_dim = 10\n",
    "num_layers = 3\n",
    "output_dim = 5\n",
    "\n",
    "#TODO change arbitrary weight\n",
    "ori_rel_weight = 2\n",
    "\n",
    "num_eps = 1\n",
    "\n",
    "num_epochs = 200\n",
    "learning_rate = 0.003\n",
    "\n",
    "base_dset_dir = os.path.expanduser('~/datasets/screwing/')\n",
    "# xprmnt_dir = time.strftime(\"/2022-03-10_23-17-39\")\n",
    "xprmnt_dir = time.strftime(\"2022-03-11_17-07-13/\")\n",
    "\n",
    "log_interval = 1 \n",
    "\n",
    "train_ratio = .75\n",
    "\n",
    "\n",
    "model_save_dir = '../../../models/'\n",
    "model_name = 'model_2022-03-27_17-18-31.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "469a2a93-17ab-4e8d-8bee-bad94f2c16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScrewingModelSeq(input_dim, hidden_dim, num_layers, output_dim)\n",
    "model.load_state_dict(torch.load(model_save_dir + model_name))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4accbae8-8ff8-4643-b9d5-142067b666b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]  Data folder /home/serialexperimentsleon/datasets/screwing/2022-03-11_17-07-13/0_2022-03-11-17-07-18 already exists. Not creating.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bag_path_names = base_dset_dir + xprmnt_dir + '*.bag' \n",
    "\n",
    "bag_path_list = glob.glob(bag_path_names)\n",
    "total_num_eps = len(bag_path_list)\n",
    "wandb.config.update({'total_dset_eps_num': num_eps})\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "dset_list = []\n",
    "for i in range(num_eps): # for testing a small number of data\n",
    "# for i in range(total_num_eps):\n",
    "    id_str = str(i)\n",
    "    bag_path_names = base_dset_dir + xprmnt_dir + id_str + '_*.bag' \n",
    "    bag_path = glob.glob(bag_path_names)[0]\n",
    "\n",
    "    pos_path_name = base_dset_dir + xprmnt_dir + id_str + '_pos.npy'\n",
    "    proj_ori_path = base_dset_dir + xprmnt_dir + id_str + '_proj_ori.npy'\n",
    "    pos_ori_path_list = [pos_path_name, proj_ori_path]\n",
    "\n",
    "    dset_list.append(ScrewingDataset(bag_path, pos_ori_path_list, window_size))\n",
    "\n",
    "concat_dset = ConcatDataset(dset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e974e1be-68c6-4c4a-aab8-2b642778d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(concat_dset)\n",
    "train_size = int(train_ratio*length)\n",
    "# train_size\n",
    "torch_seed = 0\n",
    "torch.manual_seed(torch_seed)\n",
    "train_dset, valid_dset = torch.utils.data.random_split(concat_dset, [train_size,length - train_size])\n",
    "train_dset_length = len(train_dset)\n",
    "valid_dset_length = len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "002a4235-9449-43da-8721-a17fc8cd8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_lder = DataLoader(\n",
    "    valid_dset,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3482796c-c545-4f89-9d14-5c2091050828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45473598110118224\n",
      "tensor([0.3854], device='cuda:0')\n",
      "0.32584792375564575\n",
      "0.4114879369735718\n",
      "13.464705228805542\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx,(x,y, times, T) in enumerate(valid_lder):\n",
    "        x = x.to(device)\n",
    "        y = y.float().to(device)\n",
    "\n",
    "        # Forward propogation happens here\n",
    "        outputs = model(x).to(device)\n",
    "        t = 0\n",
    "        # print(outputs.size())\n",
    "        output_t = outputs[:, t, :]\n",
    "        # print(output_t.size()) # B x L x O\n",
    "        # print(outputs[0, t, :].size()) # B x L x O\n",
    "        \n",
    "        # print(times.size()) # B x L \n",
    "        print(times[:, t].item()) \n",
    "        \n",
    "        loss = weighted_MSE_loss(output_t, y, ori_rel_weight)\n",
    "        print(batched_ori_err(output_t, y, device))\n",
    "        print(batched_pos_err(output_t, y).item())\n",
    "        print(loss.item())\n",
    "        print(T.item())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f85469-ef2d-4cb9-b180-9707bbd5a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_metrics(model, ori_rel_weight, seq_length, val_loader): #TODO add early stopping criterion\n",
    "#     # logging_step = 0\n",
    "#     # quantiles of interest: median and 95% CI\n",
    "#     q = torch.as_tensor([0.025, 0.5, 0.975]).to(device) \n",
    "#     q_timing = torch.as_tensor([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).to(device)\n",
    "#     seq_length = seq_length\n",
    "#     ## switch model to eval\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for batch_idx,(x,y, times) in enumerate(val_loader):\n",
    "#             x = x.to(device)\n",
    "#             y = y.float().to(device)\n",
    "\n",
    "#             # Forward propogation happens here\n",
    "#             outputs = model(x).to(device)\n",
    "#             for t in range(seq_length):\n",
    "\n",
    "#                 output_t = outputs[:, t, :]\n",
    "#                 times_t = times[:, t] \n",
    "\n",
    "#                 loss = weighted_MSE_loss(output_t, y, ori_rel_weight)\n",
    "\n",
    "#                 ## evaluate and append analysis metrics\n",
    "#                 total_valid_ori_error.append(batched_ori_err(output_t, y))\n",
    "#                 total_valid_pos_error.append(batched_pos_err(output_t, y))\n",
    "#                 total_valid_loss.append(loss)\n",
    "\n",
    "#                 # if batch_idx % log_interval == 0:\n",
    "#                 #     wandb.log({\"loss\": loss, 'epoch': epoch, 'batch_idx': batch_idx})\n",
    "                \n",
    "#                 total_valid_pos_error = torch.cat(total_valid_pos_error).to(device)\n",
    "#                 total_valid_ori_error = torch.cat(total_valid_ori_error).to(device)\n",
    "#                 total_valid_loss = torch.as_tensor(total_valid_loss).to(device)\n",
    "\n",
    "#                 ## statistical metrics from the test evaluations\n",
    "\n",
    "#                 ## pos error\n",
    "#                 pos_err_mean = torch.mean(total_valid_pos_error)\n",
    "#                 pos_err_std = torch.std(total_valid_pos_error)\n",
    "#                 pos_err_max = torch.max(total_valid_pos_error)\n",
    "#                 pos_err_min = torch.min(total_valid_pos_error)\n",
    "\n",
    "#                 ## 95% confidence interval and median\n",
    "#                 # q = torch.as_tensor([0.025, 0.5, 0.975]) \n",
    "#                 pos_err_95_median = torch.quantile(total_valid_pos_error, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 ## ori error\n",
    "#                 ori_err_mean = torch.mean(total_valid_ori_error)\n",
    "#                 ori_err_std = torch.std(total_valid_ori_error)\n",
    "#                 ori_err_max = torch.max(total_valid_ori_error)\n",
    "#                 ori_err_min = torch.min(total_valid_ori_error)\n",
    "\n",
    "#                 ## 95% confidence interval\n",
    "#                 ori_err_95_median = torch.quantile(total_valid_ori_error, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 ## loss \n",
    "#                 loss_mean = torch.mean(total_valid_loss)\n",
    "#                 loss_std = torch.std(total_valid_loss)\n",
    "#                 loss_max = torch.max(total_valid_loss)\n",
    "#                 loss_min = torch.min(total_valid_loss)\n",
    "\n",
    "#                 ## 95% confidence interval\n",
    "#                 loss_95_median = torch.quantile(total_valid_loss, q, dim=0, keepdim=False, interpolation='nearest')\n",
    "\n",
    "#                 wandb.log({ \n",
    "#                 'valid_pos_err_mean_' + str(t) : pos_err_mean,\n",
    "#                 'valid_pos_err_std_' + str(t) : pos_err_std,\n",
    "#                 'valid_pos_err_max_' + str(t) : pos_err_max,\n",
    "#                 'valid_pos_err_min_' + str(t) : pos_err_min,\n",
    "#                 'valid_pos_err_95_lower_' + str(t) : pos_err_95_median[0].item(),\n",
    "#                 'valid_pos_err_median_' + str(t) : pos_err_95_median[1].item(),\n",
    "#                 'valid_pos_err_95_upper_' + str(t) : pos_err_95_median[2].item(),\n",
    "#                 'valid_ori_err_mean_' + str(t) : ori_err_mean,\n",
    "#                 'valid_ori_err_std_' + str(t) : ori_err_std,\n",
    "#                 'valid_ori_err_max_' + str(t) : ori_err_max,\n",
    "#                 'valid_ori_err_min_' + str(t) : ori_err_min,\n",
    "#                 'valid_ori_err_95_lower_' + str(t) : ori_err_95_median[0].item(),\n",
    "#                 'valid_ori_err_median_' + str(t) : ori_err_95_median[1].item(),\n",
    "#                 'valid_ori_err_95_upper_' + str(t) : ori_err_95_median[2].item(),\n",
    "#                 'valid_loss_mean_' + str(t) : loss_mean,\n",
    "#                 'valid_loss_std_' + str(t) : loss_std,\n",
    "#                 'valid_loss_max_' + str(t) : loss_max,\n",
    "#                 'valid_loss_min_' + str(t) : loss_min,\n",
    "#                 'valid_loss_95_lower_' + str(t) : loss_95_median[0].item(),\n",
    "#                 'valid_loss_median_' + str(t) : loss_95_median[1].item(),\n",
    "#                 'valid_loss_95_upper_' + str(t) : loss_95_median[2].item()\n",
    "#                 }, step = logging_step-1)\n",
    "#                 ## log some summary metrics from the validation/eval run\n",
    "\n",
    "#                 ## log a figure of model output  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
